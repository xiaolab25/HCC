{"cells":[{"cell_type":"markdown","id":"MI5B_0HmNzx9","metadata":{"id":"MI5B_0HmNzx9"},"source":["# scRNA-seq batch integration and cell-type annotation\n","related to sup fig1\n","## Overview\n","\n","**Inputs (under `./data/`):** `GSE149614.h5ad`, `GSE151530.h5ad`, `GSE156625.h5ad`, `skrx2fz79n.h5ad` (Mendeley ID: skrx2fz79n).  \n","Each input must contain **raw counts** in `.X` (or provide `layers['counts']`), and must include a per-cell **sample identity** column in `.obs` (configured below).\n","\n","**Outputs (under `./outputs/`):**\n","- Integrated AnnData: `./outputs/HCC_integrated_harmony.h5ad`\n","- Key figures: `./outputs/figures/umap_*.pdf`, `./outputs/figures/dotplot_markers_*.pdf`\n","- Cluster markers (Wilcoxon): `./outputs/rank_genes_groups_leiden_res1p2.csv`\n","- Run metadata: `./outputs/config.json`, `./outputs/filtering_summary.json`\n"]},{"cell_type":"code","execution_count":null,"id":"mYEdFs_dNzx_","metadata":{"id":"mYEdFs_dNzx_"},"outputs":[],"source":["from __future__ import annotations\n","\n","import json\n","import random\n","import warnings\n","from pathlib import Path\n","\n","import numpy as np\n","import pandas as pd\n","\n","import anndata as ad\n","import scanpy as sc\n","\n","warnings.simplefilter(\"ignore\", category=UserWarning)\n","sc.set_figure_params(dpi=120, frameon=False)\n","\n","# =========================\n","# CONFIG\n","# =========================\n","CONFIG = {\n","    \"random_seed\": 0,\n","\n","    \"dataset_key\": \"dataset\",\n","    \"sample_key\": \"sample\",\n","    \"min_genes_per_cell\": 300,\n","    \"max_genes_per_cell\": 6000,\n","    \"max_pct_mito\": 20.0,\n","    \"min_cells_per_gene\": 3,\n","\n","    \"target_sum\": 1e4,\n","\n","    \"n_hvg\": 2000,\n","    \"hvg_flavor\": \"seurat_v3\",\n","    \"n_pcs\": 50,\n","    \"harmony_n_pcs\": 20,\n","\n","    \"n_neighbors\": 15,\n","    \"leiden_resolution\": 1.2,\n","\n","    \"rank_genes_method\": \"wilcoxon\",\n","\n","    \"run_scrublet\": True,\n","    \"remove_predicted_doublets\": True,\n","    \"scrublet_expected_doublet_rate\": 0.06,\n","\n","    \"exclude_clusters\": [],            # e.g. [\"7\",\"13\"]\n","\n","    \"cluster_to_celltype\": {},         # e.g. {\"0\": \"T\", \"1\": \"Myeloid\", ...}\n","}\n","\n","SAMPLE_KEY_FALLBACKS = [\"S_ID\", \"orig.ident\", \"patient\", \"donor\", \"sample_id\"]\n","\n","DATA_DIR = Path(\"./data\")\n","OUT_DIR = Path(\"./outputs\")\n","FIG_DIR = OUT_DIR / \"figures\"\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","FIG_DIR.mkdir(parents=True, exist_ok=True)\n","\n","INPUTS = {\n","    \"GSE151530\": DATA_DIR / \"GSE151530.h5ad\",\n","    \"GSE156625\": DATA_DIR / \"GSE156625.h5ad\",\n","    \"GSE149614\": DATA_DIR / \"GSE149614.h5ad\",\n","    \"skrx2fz79n\": DATA_DIR / \"skrx2fz79n.h5ad\",\n","}\n","\n","SEED = int(CONFIG[\"random_seed\"])\n","RES_TAG = str(CONFIG[\"leiden_resolution\"]).replace(\".\", \"p\")\n","random.seed(SEED)\n","np.random.seed(SEED)\n","\n","print(\"scanpy:\", sc.__version__)\n","print(\"anndata:\", ad.__version__)\n","try:\n","    import harmonypy as hm\n","    import harmonypy\n","    print(\"harmonypy:\", harmonypy.__version__)\n","except Exception:\n","    print(\"harmonypy: not available (required for Harmony integration)\")\n","try:\n","    import scrublet\n","    import scrublet as scr\n","    print(\"scrublet:\", getattr(scrublet, \"__version__\", \"unknown\"))\n","except Exception:\n","    print(\"scrublet: not available (optional; required if CONFIG['run_scrublet']=True)\")\n","\n","print(\"DATA_DIR:\", DATA_DIR.resolve())\n","print(\"OUT_DIR :\", OUT_DIR.resolve())\n"]},{"cell_type":"markdown","id":"9u2Yj1PpNzyA","metadata":{"id":"9u2Yj1PpNzyA"},"source":["## Data loading"]},{"cell_type":"code","execution_count":null,"id":"exmw9l6gNzyA","metadata":{"id":"exmw9l6gNzyA"},"outputs":[],"source":["adatas = []\n","keys = []\n","\n","missing_files = [str(p) for p in INPUTS.values() if not p.exists()]\n","if missing_files:\n","    raise FileNotFoundError(\n","        \"Missing input .h5ad file(s) under ./data/. Expected:\\n- \"\n","        + \"\\n- \".join(missing_files)\n","    )\n","\n","for ds, path in INPUTS.items():\n","    a = sc.read_h5ad(path)\n","    a.var_names_make_unique()\n","    adatas.append(a)\n","    keys.append(ds)\n","\n","adata = ad.concat(\n","    adatas,\n","    join=\"inner\",\n","    label=CONFIG[\"dataset_key\"],\n","    keys=keys,\n","    index_unique=\"-\",\n","    merge=\"same\",\n",")\n","\n","# Ensure a raw-count layer exists\n","if \"counts\" not in adata.layers:\n","    adata.layers[\"counts\"] = adata.X.copy()\n","\n","# Validate (or auto-fallback) sample key\n","sample_key = CONFIG[\"sample_key\"]\n","if sample_key not in adata.obs.columns:\n","    for cand in SAMPLE_KEY_FALLBACKS:\n","        if cand in adata.obs.columns:\n","            print(f\"INFO: sample_key '{sample_key}' not found; using fallback '{cand}'.\")\n","            sample_key = cand\n","            break\n","    else:\n","        cols = list(adata.obs.columns)\n","        raise KeyError(\n","            f\"Missing sample identity column '{CONFIG['sample_key']}' in adata.obs.\\n\"\n","            f\"Available obs columns (first 40): {cols[:40]}\"\n","        )\n","CONFIG[\"sample_key\"] = sample_key\n","\n","# Lightweight sanity checks\n","print(\"Merged AnnData:\", adata)\n","print(\"Datasets:\", adata.obs[CONFIG[\"dataset_key\"]].value_counts().to_dict())\n","print(\"Sample key:\", CONFIG[\"sample_key\"], \"| n_samples =\", adata.obs[CONFIG[\"sample_key\"]].nunique())\n"]},{"cell_type":"markdown","id":"Vl2JKPHRNzyA","metadata":{"id":"Vl2JKPHRNzyA"},"source":["## Workflow\n","\n","1) Concatenate datasets on shared genes (inner join).  \n","2) QC filtering: 300–6,000 detected genes per cell and <20% mitochondrial fraction; remove genes detected in <3 cells.  \n","3) Normalize counts to 10,000 per cell and log1p-transform.  \n","4) Select HVGs (n=2,000) using Seurat v3 procedure on raw counts with dataset-of-origin as batch covariate.  \n","5) PCA → Harmony integration (harmonypy) on the first 20 PCs with sample identity as batch covariate → neighbors/UMAP/Leiden (**resolution = 1.2**).  \n","6) Doublet detection with Scrublet and optional removal of predicted doublets.  \n","7) Marker discovery (Wilcoxon) and **manual major cell-type annotation** by inspecting cluster markers/dotplots and mapping Leiden clusters to broad lineages (`adata.obs['majortype']`).  \n","8) Export marker tables, key figures, and the final integrated `.h5ad` object + run metadata.\n"]},{"cell_type":"code","execution_count":null,"id":"R5zjhjb1NzyB","metadata":{"id":"R5zjhjb1NzyB"},"outputs":[],"source":["# =========================\n","# QC, normalization, HVGs, PCA, Harmony integration, UMAP, Leiden\n","# =========================\n","from scipy import sparse\n","\n","# --- QC ---\n","Xc = adata.layers[\"counts\"]\n","var_upper = adata.var_names.str.upper()\n","mt_mask = var_upper.str.startswith(\"MT-\").to_numpy()\n","\n","if sparse.issparse(Xc):\n","    total_counts = np.asarray(Xc.sum(axis=1)).ravel()\n","    n_genes = np.asarray((Xc > 0).sum(axis=1)).ravel()\n","    mt_counts = np.asarray(Xc[:, mt_mask].sum(axis=1)).ravel() if mt_mask.any() else np.zeros(adata.n_obs)\n","else:\n","    total_counts = Xc.sum(axis=1)\n","    n_genes = (Xc > 0).sum(axis=1)\n","    mt_counts = Xc[:, mt_mask].sum(axis=1) if mt_mask.any() else np.zeros(adata.n_obs)\n","\n","pct_mt = mt_counts / np.maximum(total_counts, 1) * 100.0\n","adata.obs[\"total_counts\"] = total_counts\n","adata.obs[\"n_genes_by_counts\"] = n_genes\n","adata.obs[\"pct_counts_mt\"] = pct_mt\n","\n","qc_mask = (\n","    (adata.obs[\"n_genes_by_counts\"] >= CONFIG[\"min_genes_per_cell\"])\n","    & (adata.obs[\"n_genes_by_counts\"] <= CONFIG[\"max_genes_per_cell\"])\n","    & (adata.obs[\"pct_counts_mt\"] < CONFIG[\"max_pct_mito\"])\n",")\n","n0 = adata.n_obs\n","adata = adata[qc_mask].copy()\n","print(f\"QC filter cells: {n0} -> {adata.n_obs}\")\n","\n","Xc = adata.layers[\"counts\"]\n","if sparse.issparse(Xc):\n","    gene_ncells = np.asarray((Xc > 0).sum(axis=0)).ravel()\n","else:\n","    gene_ncells = (Xc > 0).sum(axis=0)\n","keep_genes = gene_ncells >= int(CONFIG[\"min_cells_per_gene\"])\n","g0 = adata.n_vars\n","adata = adata[:, keep_genes].copy()\n","print(f\"Filter genes (min_cells={CONFIG['min_cells_per_gene']}): {g0} -> {adata.n_vars}\")\n","\n","# --- Scrublet ---\n","if CONFIG[\"run_scrublet\"]:\n","    try:\n","        import scrublet as scr\n","    except Exception as e:\n","        raise ImportError(\"Scrublet is required when CONFIG['run_scrublet']=True.\") from e\n","\n","    Xc = adata.layers[\"counts\"]\n","    scores = np.full(adata.n_obs, np.nan, dtype=float)\n","    preds = np.zeros(adata.n_obs, dtype=bool)\n","\n","    sample_key = CONFIG[\"sample_key\"]\n","    for s in adata.obs[sample_key].unique():\n","        idx = np.where(adata.obs[sample_key].to_numpy() == s)[0]\n","        if idx.size < 50:\n","            # too small to run robustly; mark as non-doublet by default\n","            continue\n","\n","        Xm = Xc[idx]\n","        scrub = scr.Scrublet(\n","            Xm,\n","            expected_doublet_rate=float(CONFIG[\"scrublet_expected_doublet_rate\"]),\n","        )\n","        sc_score, sc_pred = scrub.scrub_doublets()\n","        scores[idx] = sc_score\n","        preds[idx] = sc_pred\n","\n","    adata.obs[\"doublet_score\"] = scores\n","    adata.obs[\"predicted_doublet\"] = preds\n","\n","    if CONFIG[\"remove_predicted_doublets\"]:\n","        n0 = adata.n_obs\n","        adata = adata[~adata.obs[\"predicted_doublet\"].fillna(False)].copy()\n","        print(f\"Remove predicted doublets: {n0} -> {adata.n_obs}\")\n","\n","Xc = adata.layers[\"counts\"]\n","if sparse.issparse(Xc):\n","    Xc = Xc.tocsr()\n","    libsize = np.asarray(Xc.sum(axis=1)).ravel()\n","    scale = float(CONFIG[\"target_sum\"]) / np.maximum(libsize, 1)\n","    Xn = Xc.multiply(scale[:, None]).tocsr()\n","    Xn = Xn.copy()\n","    Xn.data = np.log1p(Xn.data)\n","else:\n","    libsize = Xc.sum(axis=1)\n","    scale = float(CONFIG[\"target_sum\"]) / np.maximum(libsize, 1)\n","    Xn = np.log1p(Xc * scale[:, None])\n","\n","adata.layers[\"log1p\"] = Xn\n","adata.X = adata.layers[\"log1p\"]\n","\n","try:\n","    sc.pp.highly_variable_genes(\n","        adata,\n","        flavor=str(CONFIG[\"hvg_flavor\"]),\n","        n_top_genes=int(CONFIG[\"n_hvg\"]),\n","        batch_key=CONFIG[\"dataset_key\"],\n","        layer=\"counts\",\n","    )\n","except TypeError:\n","    adata_tmp = adata.copy()\n","    adata_tmp.X = adata_tmp.layers[\"counts\"]\n","    sc.pp.highly_variable_genes(\n","        adata_tmp,\n","        flavor=str(CONFIG[\"hvg_flavor\"]),\n","        n_top_genes=int(CONFIG[\"n_hvg\"]),\n","        batch_key=CONFIG[\"dataset_key\"],\n","    )\n","    adata.var[\"highly_variable\"] = adata_tmp.var[\"highly_variable\"].values\n","\n","adata = adata[:, adata.var[\"highly_variable\"]].copy()\n","print(\"HVGs retained:\", adata.n_vars)\n","\n","# --- PCA ---\n","sc.pp.pca(adata, n_comps=int(CONFIG[\"n_pcs\"]), svd_solver=\"arpack\")\n","\n","# --- Harmony integration ---\n","try:\n","    import harmonypy as hm\n","except Exception as e:\n","    raise ImportError(\"harmonypy is required for Harmony integration.\") from e\n","\n","Z = adata.obsm[\"X_pca\"][:, : int(CONFIG[\"harmony_n_pcs\"])]\n","meta = adata.obs[[CONFIG[\"sample_key\"]]].copy()\n","ho = hm.run_harmony(Z, meta, vars_use=[CONFIG[\"sample_key\"]], max_iter_harmony=50)\n","adata.obsm[\"X_pca_harmony\"] = ho.Z_corr.T\n","\n","sc.pp.neighbors(adata, n_neighbors=int(CONFIG[\"n_neighbors\"]), use_rep=\"X_pca_harmony\")\n","sc.tl.umap(adata, random_state=SEED)\n","cluster_key = \"leiden\"\n","sc.tl.leiden(adata, resolution=float(CONFIG[\"leiden_resolution\"]), key_added=cluster_key)\n","\n","if CONFIG[\"exclude_clusters\"]:\n","    n0 = adata.n_obs\n","    adata = adata[~adata.obs[cluster_key].isin(list(CONFIG[\"exclude_clusters\"]))].copy()\n","    print(f\"Exclude clusters {CONFIG['exclude_clusters']}: {n0} -> {adata.n_obs}\")\n","\n","print(\"Computed:\", \"X_pca_harmony\", \"|\", \"UMAP\", \"|\", cluster_key, f\"(res={CONFIG['leiden_resolution']})\", \"| n_clusters =\", adata.obs[cluster_key].nunique())\n","print(\"Next:\", \"rank_genes_groups → manual cluster→majortype mapping (see below).\")\n"]},{"cell_type":"markdown","id":"knVexeipNzyB","metadata":{"id":"knVexeipNzyB"},"source":["## Results & exports\n","\n","This section exports (i) cluster marker tables, (ii) key UMAPs and marker dotplots, (iii) the manual cluster→cell-type mapping, and (iv) the final integrated `.h5ad` object plus run metadata under `./outputs/`.\n"]},{"cell_type":"code","execution_count":null,"id":"0byiFyhBNzyB","metadata":{"id":"0byiFyhBNzyB"},"outputs":[],"source":["# =========================\n","# Differential markers per Leiden cluster (Wilcoxon) + export\n","# =========================\n","cluster_key = \"leiden\"\n","\n","sc.tl.rank_genes_groups(adata, groupby=cluster_key, method=str(CONFIG[\"rank_genes_method\"]))\n","\n","groups = (\n","    list(adata.obs[cluster_key].cat.categories)\n","    if hasattr(adata.obs[cluster_key], \"cat\")\n","    else sorted(adata.obs[cluster_key].unique())\n",")\n","\n","dfs = []\n","for g in groups:\n","    df = sc.get.rank_genes_groups_df(adata, group=g)\n","    df.insert(0, \"cluster\", g)\n","    dfs.append(df)\n","\n","markers_df = pd.concat(dfs, axis=0, ignore_index=True)\n","\n","markers_csv = OUT_DIR / f\"rank_genes_groups_{cluster_key}_res{RES_TAG}.csv\"\n","markers_df.to_csv(markers_csv, index=False)\n","\n","print(\"Saved:\", markers_csv)\n"]},{"cell_type":"code","execution_count":null,"id":"uHVr-JneNzyB","metadata":{"id":"uHVr-JneNzyB"},"outputs":[],"source":["# =========================\n","# UMAPs + marker dotplots + manual cell-type annotation\n","# =========================\n","import matplotlib.pyplot as plt\n","\n","cluster_key = \"leiden\"  # Leiden at resolution = CONFIG[\"leiden_resolution\"] (here: 1.2)\n","\n","def save_umap(color, fname, **kwargs):\n","    sc.pl.umap(adata, color=color, show=False, **kwargs)\n","    plt.savefig(FIG_DIR / fname, bbox_inches=\"tight\")\n","    plt.close()\n","\n","# --- UMAPs (QC/integration outputs) ---\n","save_umap([CONFIG[\"dataset_key\"]], \"umap_by_dataset.pdf\", wspace=0.4)\n","save_umap([CONFIG[\"sample_key\"]], \"umap_by_sample.pdf\", wspace=0.4)\n","save_umap([cluster_key], \"umap_by_cluster.pdf\", wspace=0.4)\n","if \"predicted_doublet\" in adata.obs.columns:\n","    save_umap([\"predicted_doublet\"], \"umap_by_predicted_doublet.pdf\", wspace=0.4)\n","\n","# --- Canonical markers for broad lineages (used for manual annotation) ---\n","marker_genes_dict = {\n","    \"B cell\": [\"CD79A\", \"CD79B\", \"MS4A1\"],\n","    \"Plasma\": [\"CD38\", \"XBP1\"],\n","    \"T cell\": [\"CD3D\", \"CD3E\", \"CD8A\", \"CD8B\"],\n","    \"Myeloid\": [\"CD163\", \"CD68\", \"LYZ\"],\n","    \"Epithelial\": [\"EPCAM\", \"KRT18\", \"KRT8\"],\n","    \"Endothelial\": [\"VWF\", \"PECAM1\", \"ENG\"],\n","    \"Fibroblast\": [\"DCN\", \"COL1A1\", \"COL1A2\", \"LUM\"],\n","}\n","\n","marker_genes_dict = {k: [g for g in v if g in adata.var_names] for k, v in marker_genes_dict.items()}\n","marker_genes_dict = {k: v for k, v in marker_genes_dict.items() if len(v) > 0}\n","\n","# Dotplot by Leiden clusters (res=1.2)\n","sc.pl.dotplot(\n","    adata,\n","    marker_genes_dict,\n","    groupby=cluster_key,\n","    standard_scale=\"var\",\n","    show=False,\n",")\n","plt.savefig(FIG_DIR / f\"dotplot_markers_by_{cluster_key}.pdf\", bbox_inches=\"tight\")\n","plt.close()\n","\n","# =========================\n","# Manual annotation (cluster → broad lineage)\n","# =========================\n","\n","merge_dict = {\n","    '0':  'Fibro',\n","    '1':  'T&NK',\n","    '2':  'T&NK',\n","    '3':  'T&NK',\n","    '4':  'Endo',\n","    '5':  'Endo',\n","    '6':  'Endo',\n","    '7':  'Hepato',\n","    '8':  'Hepato',\n","    '9':  'Hepato',\n","    '10': 'Myeloid',\n","    '11': 'Plasma',\n","    '12': 'Myeloid',\n","    '13': 'Myeloid',\n","    '14': 'Hepato',\n","    '15': 'Hepato',\n","    '16': 'Hepato',\n","    '17': 'Hepato',\n","    '18': 'Myeloid',\n","    '19': 'T&NK',\n","    '20': 'T&NK',\n","    '21': 'T&NK',\n","    '22': 'T&NK',\n","    '23': 'T&NK',\n","    '24': 'T&NK',\n","    '25': 'T&NK',\n","    '26': 'Myeloid',\n","    '27': 'Hepato',\n","    '28': 'T&NK',\n","    '29': 'Myeloid',\n","    '30': 'Myeloid',\n","    '31': 'B',\n","    '32': 'Hepato',\n","    '33': 'Hepato',\n","    '34': 'T&NK',\n","    '35': 'Hepato',\n","    '36': 'Hepato',\n","    '37': 'T&NK',\n","    '38': 'Myeloid',\n","    '39': 'Hepato',\n","    '40': 'Hepato',\n","    '41': 'T&NK',\n","}\n","\n","\n","# Store mapping into CONFIG for provenance\n","CONFIG[\"cluster_to_celltype\"] = merge_dict\n","\n","raw_cluster = adata.obs[cluster_key].astype(str)\n","mapped = raw_cluster.map(merge_dict)\n","\n","adata.obs[\"majortype\"] = mapped.fillna(\"Unassigned\").astype(\"category\")\n","\n","# Save a UMAP colored by manual majortype labels\n","save_umap([\"majortype\"], \"umap_by_majortype.pdf\", wspace=0.4)\n","\n","# Dotplot by manual majortype labels (+ dendrogram for readability)\n","try:\n","    sc.tl.dendrogram(adata, groupby=\"majortype\")\n","    dendro = True\n","except Exception:\n","    dendro = False\n","\n","sc.pl.dotplot(\n","    adata,\n","    marker_genes_dict,\n","    groupby=\"majortype\",\n","    dendrogram=dendro,\n","    standard_scale=\"var\",\n","    show=False,\n",")\n","plt.savefig(FIG_DIR / \"dotplot_markers_by_majortype.pdf\", bbox_inches=\"tight\")\n","plt.close()\n","\n","print(\"Saved figures to:\", FIG_DIR)\n","print(\"majortype categories:\", list(adata.obs[\"majortype\"].cat.categories))\n"]},{"cell_type":"code","execution_count":null,"id":"5V77sT70NzyB","metadata":{"id":"5V77sT70NzyB"},"outputs":[],"source":["# =========================\n","# exports\n","# =========================\n","\n","out_h5ad = OUT_DIR / \"HCC_integrated_harmony.h5ad\"\n","adata.write_h5ad(out_h5ad, compression=\"gzip\")"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":["hw5qZqRijCwR","NcbHLdn7nZ6v"],"gpuType":"V6E1","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}