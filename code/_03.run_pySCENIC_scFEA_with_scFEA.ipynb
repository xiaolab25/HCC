{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5863260",
   "metadata": {
    "id": "f5863260"
   },
   "source": [
    "# pySCENIC regulon analysis\n",
    "related to extended fig1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840b98d",
   "metadata": {
    "id": "4840b98d"
   },
   "source": [
    "## Overview\n",
    "\n",
    "- **Goal:** infer TF regulons using **pySCENIC** and summarize **cell-group–specific regulon activity**.\n",
    "- **Inputs (prepared offline in `./data/`):** an AnnData `.h5ad` plus pySCENIC auxiliary resources (TF list, ranking database, motif annotations).\n",
    "- **Outputs (written to `./results/`):** loom files, AUC matrix, RSS table, top-regulon table, and key figures (PDF/PNG/SVG).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed706a6",
   "metadata": {
    "id": "6ed706a6"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CONFIG + reproducibility\n",
    "# =========================\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    import scanpy as sc\n",
    "except Exception as e:\n",
    "    raise ImportError(\"scanpy is required for this notebook.\") from e\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams[\"pdf.fonttype\"] = 42\n",
    "mpl.rcParams[\"ps.fonttype\"]  = 42\n",
    "mpl.rcParams[\"svg.fonttype\"] = \"none\"\n",
    "CONFIG = {\n",
    "    \"dataset_id\": \"HCC_new_Fibro\",\n",
    "    \"input_h5ad\": \"./outputs/h5ad/1_Fibro_count_new.h5ad\",\n",
    "    \"group_key\": \"subtype\",\n",
    "    \"layer_for_scenic\": None,  # e.g. \"counts\"\n",
    "    \"aux_dir\": \"./data/auxiliaries\",\n",
    "    \"tf_list\": \"allTFs_hg38.txt\",\n",
    "    \"ranking_db\": \"hg38_10kbp_up_10kbp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather\",\n",
    "    \"motif_annotations\": \"motifs-v10nr_clust-nr.hgnc-m0.001-o0.0.tbl\",\n",
    "    \"seed\": 0,\n",
    "    \"n_workers\": 16,\n",
    "    \"top_n_regulons_per_group\": 10,\n",
    "    \"out_dir\": \"./results/pyscenic\",\n",
    "}\n",
    "seed = int(CONFIG[\"seed\"])\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "try:\n",
    "    import torch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "except Exception:\n",
    "    pass\n",
    "dataset_id = CONFIG[\"dataset_id\"]\n",
    "out_dir = Path(CONFIG[\"out_dir\"]) / dataset_id\n",
    "fig_dir = out_dir / \"figures\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "aux_dir = Path(CONFIG[\"aux_dir\"])\n",
    "input_h5ad = Path(CONFIG[\"input_h5ad\"])\n",
    "paths = {\n",
    "    \"expr_csv\": out_dir / f\"{dataset_id}.qc.tpm.csv\",\n",
    "    \"loom_in\":  out_dir / f\"{dataset_id}.qc.count.loom\",\n",
    "    \"adj\":      out_dir / f\"{dataset_id}.adjacencies.tsv\",\n",
    "    \"motifs\":   out_dir / f\"{dataset_id}.motifs.csv\",\n",
    "    \"loom_out\": out_dir / f\"{dataset_id}.out.loom\",\n",
    "    \"auc_csv\":  out_dir / \"regulon_auc.csv.gz\",\n",
    "    \"rss_csv\":  out_dir / \"rss.csv\",\n",
    "    \"top_csv\":  out_dir / \"top_regulons_by_group.csv\",\n",
    "    \"adata_out\": out_dir / \"adata_with_regulon_auc.h5ad\",\n",
    "    \"cli_sh\":   out_dir / \"run_pyscenic.sh\",\n",
    "    \"config_json\": out_dir / \"config.json\",\n",
    "}\n",
    "def _v(modname: str):\n",
    "    try:\n",
    "        m = __import__(modname)\n",
    "        return getattr(m, \"__version__\", \"unknown\")\n",
    "    except Exception:\n",
    "        return \"not-installed\"\n",
    "versions = {\n",
    "    \"python\": f\"{os.sys.version_info.major}.{os.sys.version_info.minor}.{os.sys.version_info.micro}\",\n",
    "    \"numpy\": _v(\"numpy\"),\n",
    "    \"pandas\": _v(\"pandas\"),\n",
    "    \"scanpy\": _v(\"scanpy\"),\n",
    "    \"anndata\": _v(\"anndata\"),\n",
    "    \"pyscenic\": _v(\"pyscenic\"),\n",
    "    \"loompy\": _v(\"loompy\"),\n",
    "    \"matplotlib\": _v(\"matplotlib\"),\n",
    "    \"seaborn\": _v(\"seaborn\"),\n",
    "}\n",
    "print(json.dumps(versions, indent=2))\n",
    "Path(paths[\"config_json\"]).write_text(\n",
    "    json.dumps(\n",
    "        {\"CONFIG\": CONFIG, \"paths\": {k: str(v) for k, v in paths.items()}, \"versions\": versions},\n",
    "        indent=2,\n",
    "    )\n",
    ")\n",
    "print(f\"\\nOutputs will be written under: {out_dir.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23415fe3",
   "metadata": {
    "id": "23415fe3"
   },
   "source": [
    "## Data loading\n",
    "\n",
    "Data acquisition and preprocessing (QC, normalization, cell-type annotation) were performed **offline**.  \n",
    "The notebook assumes all required input files are already present locally under `./data/` (or provided by the authors).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20420d8b",
   "metadata": {
    "id": "20420d8b"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Data loading + minimal sanity checks\n",
    "# =========================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Fallbacks for common path variants\n",
    "if not aux_dir.exists():\n",
    "    alt_aux = Path(str(aux_dir).replace(\"auxiliaries\", \"auxilliaries\"))\n",
    "    if alt_aux.exists():\n",
    "        print(f\"INFO: aux_dir '{aux_dir}' not found; using fallback '{alt_aux}'.\")\n",
    "        aux_dir = alt_aux\n",
    "if not input_h5ad.exists():\n",
    "    alt_input = Path(\"./data/1_Fibro_count_new.h5ad\")\n",
    "    if alt_input.exists():\n",
    "        print(f\"INFO: input_h5ad '{input_h5ad}' not found; using fallback '{alt_input}'.\")\n",
    "        input_h5ad = alt_input\n",
    "ranking_db_path = aux_dir / CONFIG[\"ranking_db\"]\n",
    "if not ranking_db_path.exists():\n",
    "    raise FileNotFoundError(f\"Ranking DB not found: {ranking_db_path}\")\n",
    "try:\n",
    "    import pyarrow.feather as feather\n",
    "    ranking_genes = [c for c in feather.read_table(ranking_db_path).column_names if c != \"motifs\"]\n",
    "except Exception:\n",
    "    ranking_genes = list(pd.read_feather(ranking_db_path).columns)\n",
    "    if ranking_genes and ranking_genes[-1] == \"motifs\":\n",
    "        ranking_genes = ranking_genes[:-1]\n",
    "ranking_genes = set(ranking_genes)\n",
    "if not input_h5ad.exists():\n",
    "    raise FileNotFoundError(f\"Input h5ad not found: {input_h5ad}\")\n",
    "adata = sc.read_h5ad(input_h5ad)\n",
    "group_key = CONFIG[\"group_key\"]\n",
    "if group_key not in adata.obs.columns:\n",
    "    raise KeyError(f\"Required obs column missing: {group_key}\")\n",
    "genes_before = adata.n_vars\n",
    "keep_genes = [g for g in adata.var_names if g in ranking_genes]\n",
    "if len(keep_genes) == 0:\n",
    "    raise ValueError(\"No overlap between adata.var_names and ranking DB genes.\")\n",
    "adata = adata[:, keep_genes].copy()\n",
    "print(f\"Loaded adata: n_cells={adata.n_obs:,}  n_genes={adata.n_vars:,}  (before intersection: {genes_before:,})\")\n",
    "print(f\"Groups in adata.obs[{group_key!r}]: {adata.obs[group_key].nunique()}\")\n",
    "adata.obs[group_key] = adata.obs[group_key].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a25f95b",
   "metadata": {
    "id": "1a25f95b"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Export expression + create LOOM for pySCENIC\n",
    "# =========================\n",
    "from scipy import sparse\n",
    "\n",
    "layer = CONFIG[\"layer_for_scenic\"]\n",
    "if layer is None:\n",
    "    X = adata.X\n",
    "else:\n",
    "    if layer not in adata.layers:\n",
    "        raise KeyError(f\"layer_for_scenic={layer!r} not found in adata.layers\")\n",
    "    X = adata.layers[layer]\n",
    "\n",
    "if sparse.issparse(X):\n",
    "    X_csr = X.tocsr()\n",
    "else:\n",
    "    X_csr = sparse.csr_matrix(X)\n",
    "\n",
    "expr_df = pd.DataFrame.sparse.from_spmatrix(X_csr, index=adata.obs_names, columns=adata.var_names)\n",
    "expr_df.to_csv(paths[\"expr_csv\"], index=True)\n",
    "print(f\"Wrote expression matrix: {paths['expr_csv']}\")\n",
    "\n",
    "import loompy as lp\n",
    "import numpy as np\n",
    "\n",
    "row_attrs = {\"Gene\": np.array(adata.var_names)}\n",
    "col_attrs = {\n",
    "    \"CellID\": np.array(adata.obs_names),\n",
    "    group_key: np.array(adata.obs[group_key].values, dtype=str),\n",
    "}\n",
    "\n",
    "M = X_csr.transpose().astype(np.float32).toarray()  # genes × cells\n",
    "lp.create(str(paths[\"loom_in\"]), M, row_attrs, col_attrs)\n",
    "print(f\"Wrote LOOM input: {paths['loom_in']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed32db8",
   "metadata": {
    "id": "fed32db8"
   },
   "source": [
    "## Core analysis\n",
    "\n",
    "1. Match input genes to the cisTarget ranking database gene universe.\n",
    "2. Create a **LOOM** file for pySCENIC input.\n",
    "3. Run pySCENIC CLI (**grn → ctx → aucell**) via an autogenerated shell script (no installs/downloads here).\n",
    "4. Load the `*.out.loom`, compute **regulon specificity scores (RSS)** by a chosen `group_key`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07262b02",
   "metadata": {
    "id": "07262b02"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# pySCENIC CLI script (grn → ctx → aucell)\n",
    "# =========================\n",
    "\n",
    "\n",
    "tf_list_path = aux_dir / CONFIG[\"tf_list\"]\n",
    "motif_anno_path = aux_dir / CONFIG[\"motif_annotations\"]\n",
    "for p in [tf_list_path, motif_anno_path]:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Required auxiliary file not found: {p}\")\n",
    "\n",
    "cmds = \"#!/usr/bin/env bash\\n\"\n",
    "cmds += \"set -euo pipefail\\n\\n\"\n",
    "\n",
    "cmds += \"# GRN inference (GRNBoost2)\\n\"\n",
    "cmds += \"pyscenic grn \\\\\\n\"\n",
    "cmds += f'  \"{paths[\"loom_in\"]}\" \\\\\\n'\n",
    "cmds += f'  \"{tf_list_path}\" \\\\\\n'\n",
    "cmds += f'  -o \"{paths[\"adj\"]}\" \\\\\\n'\n",
    "cmds += f'  --num_workers {int(CONFIG[\"n_workers\"])} \\\\\\n'\n",
    "cmds += \"  --method grnboost2\\n\\n\"\n",
    "\n",
    "cmds += \"# Regulon prediction (cisTarget / ctx)\\n\"\n",
    "cmds += \"pyscenic ctx \\\\\\n\"\n",
    "cmds += f'  \"{paths[\"adj\"]}\" \\\\\\n'\n",
    "cmds += f'  \"{ranking_db_path}\" \\\\\\n'\n",
    "cmds += f'  --annotations_fname \"{motif_anno_path}\" \\\\\\n'\n",
    "cmds += f'  --expression_mtx_fname \"{paths[\"loom_in\"]}\" \\\\\\n'\n",
    "cmds += f'  --output \"{paths[\"motifs\"]}\" \\\\\\n'\n",
    "cmds += f'  --num_workers {int(CONFIG[\"n_workers\"])} \\\\\\n'\n",
    "cmds += \"  --mode custom_multiprocessing\\n\\n\"\n",
    "\n",
    "cmds += \"# AUCell scoring\\n\"\n",
    "cmds += \"pyscenic aucell \\\\\\n\"\n",
    "cmds += f'  \"{paths[\"loom_in\"]}\" \\\\\\n'\n",
    "cmds += f'  \"{paths[\"motifs\"]}\" \\\\\\n'\n",
    "cmds += f'  --output \"{paths[\"loom_out\"]}\" \\\\\\n'\n",
    "cmds += f'  --num_workers {int(CONFIG[\"n_workers\"])}\\n'\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "Path(paths[\"cli_sh\"]).write_text(cmds)\n",
    "os.chmod(paths[\"cli_sh\"], 0o755)\n",
    "\n",
    "print(f\"Wrote CLI script: {paths['cli_sh']}\")\n",
    "print(f\"Run: bash {paths['cli_sh']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f83f66",
   "metadata": {
    "id": "b7f83f66"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Load AUCell output + compute RSS\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "import loompy as lp\n",
    "import numpy as np\n",
    "\n",
    "if not Path(paths[\"loom_out\"]).exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing AUCell output loom: {paths['loom_out']}\\n\"\n",
    "        f\"Run the generated CLI script first: bash {paths['cli_sh']}\"\n",
    "    )\n",
    "\n",
    "def load_regulon_auc_from_loom(loom_path: str) -> pd.DataFrame:\n",
    "    # Robustly load regulon AUC from a pySCENIC `*.out.loom`.\n",
    "    # Returns: DataFrame with index=CellID and columns=regulon names (best-effort).\n",
    "    with lp.connect(loom_path, mode=\"r\") as lf:\n",
    "        if \"RegulonsAUC\" not in lf.ca:\n",
    "            raise KeyError(\"Expected column attribute 'RegulonsAUC' not found in loom.ca\")\n",
    "\n",
    "        cell_ids = lf.ca[\"CellID\"]\n",
    "        cell_ids = np.array(cell_ids).astype(str)\n",
    "\n",
    "        arr = np.array(lf.ca[\"RegulonsAUC\"])\n",
    "        if arr.shape[0] == len(cell_ids):\n",
    "            auc = pd.DataFrame(arr, index=cell_ids)\n",
    "        elif arr.shape[1] == len(cell_ids):\n",
    "            auc = pd.DataFrame(arr.T, index=cell_ids)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected RegulonsAUC shape={arr.shape} vs n_cells={len(cell_ids)}\")\n",
    "\n",
    "        reg_names = None\n",
    "        for d in [lf.ca, lf.ra]:\n",
    "            for k in d.keys():\n",
    "                v = d[k]\n",
    "                if isinstance(v, np.ndarray) and v.ndim == 1 and len(v) == auc.shape[1] and (\"regulon\" in k.lower()):\n",
    "                    reg_names = list(v.astype(str))\n",
    "                    break\n",
    "            if reg_names is not None:\n",
    "                break\n",
    "\n",
    "        if reg_names is None:\n",
    "            reg_names = [f\"Regulon_{i}\" for i in range(auc.shape[1])]\n",
    "\n",
    "        auc.columns = reg_names\n",
    "        return auc\n",
    "\n",
    "auc_mtx = load_regulon_auc_from_loom(str(paths[\"loom_out\"]))\n",
    "\n",
    "common_cells = adata.obs_names.intersection(auc_mtx.index)\n",
    "if len(common_cells) == 0:\n",
    "    raise ValueError(\"No overlapping CellIDs between input adata and out.loom AUC matrix.\")\n",
    "auc_mtx = auc_mtx.loc[common_cells]\n",
    "adata_sub = adata[common_cells].copy()\n",
    "\n",
    "print(f\"AUC matrix: cells={auc_mtx.shape[0]:,} regulons={auc_mtx.shape[1]:,}\")\n",
    "auc_mtx.to_csv(paths[\"auc_csv\"], compression=\"gzip\")\n",
    "print(f\"Wrote: {paths['auc_csv']}\")\n",
    "\n",
    "from pyscenic.rss import regulon_specificity_scores\n",
    "rss = regulon_specificity_scores(auc_mtx, adata_sub.obs[group_key])\n",
    "rss.to_csv(paths[\"rss_csv\"])\n",
    "print(f\"Wrote: {paths['rss_csv']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b9efe",
   "metadata": {
    "id": "b93b9efe"
   },
   "source": [
    "## Results & exports\n",
    "\n",
    "This section saves:\n",
    "- `regulon_auc.csv.gz` (cells × regulons)\n",
    "- `rss.csv` (regulons × groups)\n",
    "- `top_regulons_by_group.csv`\n",
    "- figures: `rss_heatmap.*`, `rss_barplots.*`, and optional UMAP overlays if available\n",
    "- `adata_with_regulon_auc.h5ad` (AnnData augmented with regulon AUC in `obsm`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a7521",
   "metadata": {
    "id": "1c3a7521"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Top regulons per group + figures\n",
    "# =========================\n",
    "import seaborn as sns\n",
    "\n",
    "top_n = int(CONFIG[\"top_n_regulons_per_group\"])\n",
    "\n",
    "rows = []\n",
    "for g in rss.columns:\n",
    "    s = rss[g].sort_values(ascending=False).head(top_n)\n",
    "    for regulon, val in s.items():\n",
    "        rows.append({\"group\": g, \"regulon\": regulon, \"rss\": float(val)})\n",
    "top_tbl = pd.DataFrame(rows).sort_values([\"group\", \"rss\"], ascending=[True, False])\n",
    "top_tbl.to_csv(paths[\"top_csv\"], index=False)\n",
    "print(f\"Wrote: {paths['top_csv']}\")\n",
    "\n",
    "rss_z = rss.copy()\n",
    "for g in rss_z.columns:\n",
    "    mu = rss_z[g].mean()\n",
    "    sd = rss_z[g].std(ddof=0)\n",
    "    rss_z[g] = (rss_z[g] - mu) / (sd if sd != 0 else 1.0)\n",
    "\n",
    "top_regulons = sorted(set(top_tbl[\"regulon\"].tolist()))\n",
    "rss_z_sub = rss_z.loc[top_regulons]\n",
    "\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "g = sns.clustermap(\n",
    "    rss_z_sub,\n",
    "    cmap=\"vlag\",\n",
    "    center=0,\n",
    "    linewidths=0.2,\n",
    "    figsize=(max(6, 0.25 * rss_z_sub.shape[1] + 2), max(6, 0.18 * rss_z_sub.shape[0] + 2)),\n",
    "    yticklabels=True,\n",
    "    xticklabels=True,\n",
    ")\n",
    "heatmap_pdf = fig_dir / \"rss_heatmap.pdf\"\n",
    "heatmap_png = fig_dir / \"rss_heatmap.png\"\n",
    "g.savefig(heatmap_pdf, bbox_inches=\"tight\")\n",
    "g.savefig(heatmap_png, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(g.fig)\n",
    "print(f\"Saved: {heatmap_pdf}\")\n",
    "print(f\"Saved: {heatmap_png}\")\n",
    "\n",
    "from pyscenic.plotting import plot_rss\n",
    "n_groups = rss.shape[1]\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(n_groups / n_cols))\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 3*n_rows), squeeze=False)\n",
    "\n",
    "for ax, grp in zip(axes.ravel(), rss.columns):\n",
    "    plot_rss(rss, grp, top_n=top_n, ax=ax)\n",
    "    ax.set_title(grp)\n",
    "\n",
    "for ax in axes.ravel()[n_groups:]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "bar_pdf = fig_dir / \"rss_barplots.pdf\"\n",
    "bar_png = fig_dir / \"rss_barplots.png\"\n",
    "fig.tight_layout()\n",
    "fig.savefig(bar_pdf)\n",
    "fig.savefig(bar_png, dpi=300)\n",
    "plt.close(fig)\n",
    "print(f\"Saved: {bar_pdf}\")\n",
    "print(f\"Saved: {bar_png}\")\n",
    "\n",
    "if \"X_umap\" in adata_sub.obsm:\n",
    "    best = top_tbl.sort_values(\"rss\", ascending=False).groupby(\"group\", as_index=False).head(1)\n",
    "    regulons_to_plot = best[\"regulon\"].tolist()\n",
    "    for r in regulons_to_plot:\n",
    "        adata_sub.obs[f\"AUC:{r}\"] = auc_mtx[r].values\n",
    "\n",
    "    sc.pl.umap(\n",
    "        adata_sub,\n",
    "        color=[group_key] + [f\"AUC:{r}\" for r in regulons_to_plot],\n",
    "        wspace=0.4,\n",
    "        frameon=False,\n",
    "        show=False,\n",
    "    )\n",
    "    umap_pdf = fig_dir / \"umap_regulon_auc.pdf\"\n",
    "    plt.savefig(umap_pdf, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"Saved: {umap_pdf}\")\n",
    "else:\n",
    "    print(\"UMAP not found in adata.obsm['X_umap']; skipped UMAP overlays.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f31e22",
   "metadata": {
    "id": "88f31e22"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Save augmented AnnData (AUC in obsm) + final paths\n",
    "# =========================\n",
    "adata_sub.obsm[\"X_regulon_auc\"] = auc_mtx.values.astype(np.float32)\n",
    "adata_sub.uns[\"regulon_auc_columns\"] = list(auc_mtx.columns)\n",
    "adata_sub.uns[\"rss_table_path\"] = str(paths[\"rss_csv\"])\n",
    "adata_sub.uns[\"top_regulons_table_path\"] = str(paths[\"top_csv\"])\n",
    "\n",
    "adata_sub.write_h5ad(paths[\"adata_out\"])\n",
    "print(f\"Wrote: {paths['adata_out']}\")\n",
    "\n",
    "print(\"\\nKey outputs:\")\n",
    "for k in [\"cli_sh\", \"loom_in\", \"adj\", \"motifs\", \"loom_out\", \"auc_csv\", \"rss_csv\", \"top_csv\", \"adata_out\"]:\n",
    "    print(f\"- {k}: {paths[k]}\")\n",
    "print(f\"- figures: {fig_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04tFvtuiL6O",
   "metadata": {
    "id": "a04tFvtuiL6O"
   },
   "source": [
    "# scFEA metabolic flux analysis (Fibro example)\n",
    "related to extended fig1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9204efb",
   "metadata": {
    "id": "d9204efb"
   },
   "source": [
    "**Inputs (in `./data/`).**\n",
    "1. `1_Fibro_count_new.h5ad`: AnnData with `obs['subtype']` (fibroblast subtypes).\n",
    "2. `Fibro_flux.csv`: scFEA-predicted flux matrix (`cells × modules`, columns like `M_1 ...`).  \n",
    "3. `Human_M168_information.symbols.csv`: module annotations (at least `Compound_IN_name`, `Compound_OUT_name`).\n",
    "\n",
    "**Outputs (written to `./outputs/scfea_fibro/`).**\n",
    "- Heatmap (PDF/SVG) of subtype signature modules (row z-scores).\n",
    "- CSV tables: mean flux per subtype, z-scored matrix, per-subtype top modules.\n",
    "- A compact `.h5ad` subset containing the matched cells and selected module fluxes (optional but reproducible).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae74ce87",
   "metadata": {
    "id": "ae74ce87"
   },
   "source": [
    "## Data loading\n",
    "\n",
    "This notebook can start from an existing `Fibro_flux.csv`.  \n",
    "If you **do not** have it yet, run the **scFEA upstream** cells below to generate it from the `.h5ad`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a5e64",
   "metadata": {
    "id": "729a5e64"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "DATA_DIR = Path(\"./data\")\n",
    "OUT_DIR  = Path(\"./outputs/scfea_fibro\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "H5AD_PATH        = DATA_DIR / \"1_Fibro_count_new.h5ad\"\n",
    "FLUX_CSV_PATH    = DATA_DIR / \"Fibro_flux.csv\"\n",
    "MODULE_INFO_PATH = DATA_DIR / \"Human_M168_information.symbols.csv\"\n",
    "\n",
    "SEED = 0\n",
    "SUBTYPE_KEY = \"subtype\"\n",
    "DROP_SUBTYPES = [\"myFibro_TAGLN\", \"Pericyte\"]\n",
    "TOP_K = 8\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "mpl.rcParams[\"pdf.fonttype\"] = 42\n",
    "mpl.rcParams[\"ps.fonttype\"]  = 42\n",
    "mpl.rcParams[\"svg.fonttype\"] = \"none\"\n",
    "\n",
    "def _safe_version(pkg_name: str) -> str:\n",
    "    try:\n",
    "        import importlib\n",
    "        mod = importlib.import_module(pkg_name)\n",
    "        return getattr(mod, \"__version__\", \"unknown\")\n",
    "    except Exception:\n",
    "        return \"not installed\"\n",
    "\n",
    "print(\"Versions:\",\n",
    "      f\"scanpy={_safe_version('scanpy')}\",\n",
    "      f\"anndata={_safe_version('anndata')}\",\n",
    "      f\"numpy={_safe_version('numpy')}\",\n",
    "      f\"pandas={_safe_version('pandas')}\",\n",
    "      f\"matplotlib={_safe_version('matplotlib')}\",\n",
    "      sep=\"\\n  - \")\n",
    "print(\"\\nCONFIG:\")\n",
    "print(\"  H5AD_PATH       =\", H5AD_PATH)\n",
    "print(\"  FLUX_CSV_PATH   =\", FLUX_CSV_PATH)\n",
    "print(\"  MODULE_INFO_PATH=\", MODULE_INFO_PATH)\n",
    "print(\"  OUT_DIR         =\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db398a0b",
   "metadata": {},
   "source": [
    "### scFEA upstream to generate Fibro_flux.csv\n",
    "\n",
    "Run this section only if `./data/Fibro_flux.csv` is missing.\n",
    "\n",
    "What it does:\n",
    "1. Subset the AnnData by fibro subtypes (drops `DROP_SUBTYPES`).\n",
    "2. Export scFEA input matrix (**genes × cells**) from raw counts if available.\n",
    "3. Call `src/scFEA.py` to generate `Fibro_flux.csv` and `Fibro_balance.csv`.\n",
    "\n",
    "Requirements:\n",
    "- A local scFEA repo checkout (set `SCFEA_DIR`, e.g. `/content/scFEA` on Colab).\n",
    "- `module_gene_m168.csv` and `cmMat_c70_m168.csv` available under `SCFEA_DIR/data/` (the code will also try to copy them from `./data/` if present).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    from scipy.sparse import issparse\n",
    "except Exception as e:\n",
    "    raise ImportError(\"scipy is required for exporting scFEA input (sparse matrix handling).\") from e\n",
    "\n",
    "# -------------------------\n",
    "# scFEA repository path\n",
    "# -------------------------\n",
    "# EDIT ME if needed:\n",
    "#   - Colab example: SCFEA_DIR = Path(\"/content/scFEA\")\n",
    "#   - Local example: SCFEA_DIR = Path(\"./scFEA\")\n",
    "SCFEA_DIR = Path(os.environ.get(\"SCFEA_DIR\", \"./scFEA\"))\n",
    "SCFEA_SRC = SCFEA_DIR / \"src\" / \"scFEA.py\"\n",
    "\n",
    "SCFEA_DATA_DIR  = SCFEA_DIR / \"data\"\n",
    "SCFEA_INPUT_DIR = SCFEA_DIR / \"input\"\n",
    "SCFEA_OUT_DIR   = SCFEA_DIR / \"output\"\n",
    "\n",
    "SCFEA_TEST_FILE = \"Fibro_scFEA_input.csv\"\n",
    "SCFEA_INPUT_CSV = SCFEA_INPUT_DIR / SCFEA_TEST_FILE\n",
    "\n",
    "# scFEA reference filenames (expected under SCFEA_DATA_DIR)\n",
    "SCFEA_MODULE_GENE_FILE = \"module_gene_m168.csv\"\n",
    "SCFEA_STOICH_FILE      = \"cmMat_c70_m168.csv\"\n",
    "\n",
    "# Where to write scFEA results used by downstream analysis\n",
    "BALANCE_CSV_PATH = DATA_DIR / \"Fibro_balance.csv\"\n",
    "\n",
    "if SCFEA_DIR.exists():\n",
    "    print(\"SCFEA_DIR:\", SCFEA_DIR.resolve())\n",
    "    print(\"SCFEA_SRC:\", SCFEA_SRC)\n",
    "else:\n",
    "    print(\"WARNING: SCFEA_DIR does not exist:\", SCFEA_DIR)\n",
    "    print(\"         If you want to run scFEA here, clone the repo and set SCFEA_DIR accordingly.\")\n",
    "\n",
    "print(\"Will use (downstream) FLUX_CSV_PATH:\", FLUX_CSV_PATH.resolve())\n",
    "print(\"Will write BALANCE_CSV_PATH:\", BALANCE_CSV_PATH.resolve())\n",
    "print(\"Will write scFEA input to:\", SCFEA_INPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27199bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_scfea_input_from_adata(\n",
    "    adata_in: sc.AnnData,\n",
    "    out_csv: Path,\n",
    "    prefer_layers=(\"raw_counts\", \"raw\"),\n",
    "    make_unique_genes: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Export scFEA input CSV (genes × cells).\n",
    "\n",
    "    scFEA expects:\n",
    "      - rows: gene symbols\n",
    "      - columns: cell IDs\n",
    "    \"\"\"\n",
    "    X = None\n",
    "    genes = None\n",
    "\n",
    "    # 1) Prefer raw-count layers if present\n",
    "    for layer in prefer_layers:\n",
    "        if layer in adata_in.layers:\n",
    "            X = adata_in.layers[layer]\n",
    "            genes = adata_in.var_names\n",
    "            print(f\"Using adata.layers['{layer}'] for scFEA input.\")\n",
    "            break\n",
    "\n",
    "    # 2) Next try adata.raw.X\n",
    "    if X is None and getattr(adata_in, \"raw\", None) is not None:\n",
    "        X = adata_in.raw.X\n",
    "        genes = adata_in.raw.var_names\n",
    "        print(\"Using adata.raw.X for scFEA input.\")\n",
    "\n",
    "    # 3) Fallback to X (make sure it is not log1p-normalized)\n",
    "    if X is None:\n",
    "        X = adata_in.X\n",
    "        genes = adata_in.var_names\n",
    "        print(\"Using adata.X for scFEA input (fallback). Make sure it is not log1p-normalized.\")\n",
    "\n",
    "    # Ensure dense (cells × genes)\n",
    "    if issparse(X):\n",
    "        X = X.toarray()\n",
    "    X = np.asarray(X)\n",
    "\n",
    "    # scFEA needs genes × cells\n",
    "    mat = X.T\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        mat,\n",
    "        index=pd.Index(genes.astype(str), name=\"gene\"),\n",
    "        columns=pd.Index(adata_in.obs_names.astype(str), name=\"cell\"),\n",
    "    )\n",
    "\n",
    "    # Sanitize CSV-breaking characters\n",
    "    df.index = df.index.str.replace(\",\", \"_\", regex=False)\n",
    "    df.columns = df.columns.str.replace(\",\", \"_\", regex=False)\n",
    "\n",
    "    # Handle duplicated gene symbols\n",
    "    if make_unique_genes and df.index.duplicated().any():\n",
    "        n_dup = int(df.index.duplicated().sum())\n",
    "        print(f\"WARNING: duplicated gene symbols detected (n={n_dup}). Collapsing by sum.\")\n",
    "        df = df.groupby(df.index, sort=False).sum()\n",
    "\n",
    "    out_csv = Path(out_csv)\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(out_csv)\n",
    "\n",
    "    print(\"Wrote scFEA input CSV:\", out_csv.resolve())\n",
    "    print(\"scFEA input shape (genes × cells):\", df.shape)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4837390",
   "metadata": {
    "id": "b4837390"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "adata_all = sc.read_h5ad(H5AD_PATH)\n",
    "if SUBTYPE_KEY not in adata_all.obs.columns:\n",
    "    raise KeyError(f\"AnnData.obs is missing required column: {SUBTYPE_KEY}\")\n",
    "\n",
    "# 1) Subset cells used for scFEA (drop unwanted subtypes)\n",
    "adata = adata_all[~adata_all.obs[SUBTYPE_KEY].isin(DROP_SUBTYPES)].copy()\n",
    "\n",
    "# 2) Clean cell IDs early (commas break CSV and will also break scFEA I/O)\n",
    "adata.obs_names = adata.obs_names.astype(str).str.replace(\",\", \"_\", regex=False)\n",
    "\n",
    "# Local path for balance output (kept for completeness)\n",
    "BALANCE_CSV_PATH = globals().get(\"BALANCE_CSV_PATH\", DATA_DIR / \"Fibro_balance.csv\")\n",
    "\n",
    "# 3) If Fibro_flux.csv is missing, try to generate it by running scFEA here\n",
    "if not FLUX_CSV_PATH.exists():\n",
    "    print(f\"Missing flux file: {FLUX_CSV_PATH} -> will try to run scFEA to generate it.\")\n",
    "\n",
    "    # If upstream config cells were not executed, define sane defaults\n",
    "    if \"SCFEA_DIR\" not in globals():\n",
    "        SCFEA_DIR = Path(os.environ.get(\"SCFEA_DIR\", \"./scFEA\"))\n",
    "        SCFEA_SRC = SCFEA_DIR / \"src\" / \"scFEA.py\"\n",
    "        SCFEA_DATA_DIR  = SCFEA_DIR / \"data\"\n",
    "        SCFEA_INPUT_DIR = SCFEA_DIR / \"input\"\n",
    "        SCFEA_OUT_DIR   = SCFEA_DIR / \"output\"\n",
    "        SCFEA_TEST_FILE = \"Fibro_scFEA_input.csv\"\n",
    "        SCFEA_INPUT_CSV = SCFEA_INPUT_DIR / SCFEA_TEST_FILE\n",
    "        SCFEA_MODULE_GENE_FILE = \"module_gene_m168.csv\"\n",
    "        SCFEA_STOICH_FILE      = \"cmMat_c70_m168.csv\"\n",
    "\n",
    "    if \"export_scfea_input_from_adata\" not in globals():\n",
    "        raise NameError(\"export_scfea_input_from_adata() not found. Run the scFEA upstream cells above first.\")\n",
    "\n",
    "    # Guardrails: only run if scFEA repo looks available\n",
    "    if not SCFEA_DIR.exists():\n",
    "        raise FileNotFoundError(\n",
    "            \"SCFEA_DIR does not exist.\\n\"\n",
    "            f\"Current SCFEA_DIR={SCFEA_DIR}\\n\"\n",
    "            \"Clone scFEA repo and/or set SCFEA_DIR (see upstream config cell).\"\n",
    "        )\n",
    "    if not SCFEA_SRC.exists():\n",
    "        raise FileNotFoundError(\n",
    "            \"Cannot find scFEA entry script.\\n\"\n",
    "            f\"Expected: {SCFEA_SRC}\\n\"\n",
    "            \"Check your scFEA repo layout (should contain 'src/scFEA.py').\"\n",
    "        )\n",
    "\n",
    "    # Ensure folders\n",
    "    SCFEA_INPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    SCFEA_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    SCFEA_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Make sure scFEA reference files exist under SCFEA_DATA_DIR\n",
    "    needed = [\n",
    "        SCFEA_DATA_DIR / SCFEA_MODULE_GENE_FILE,\n",
    "        SCFEA_DATA_DIR / SCFEA_STOICH_FILE,\n",
    "    ]\n",
    "    missing = [p for p in needed if not p.exists()]\n",
    "    if missing:\n",
    "        print(\"Missing scFEA reference files under SCFEA_DATA_DIR:\")\n",
    "        for p in missing:\n",
    "            print(\" -\", p)\n",
    "        print(\"Will try to copy from ./data/ if available ...\")\n",
    "\n",
    "        for p in missing:\n",
    "            alt = DATA_DIR / p.name\n",
    "            if alt.exists():\n",
    "                shutil.copy2(alt, p)\n",
    "                print(f\"Copied {alt} -> {p}\")\n",
    "\n",
    "        missing = [p for p in needed if not p.exists()]\n",
    "        if missing:\n",
    "            raise FileNotFoundError(\n",
    "                \"Still missing required scFEA reference files.\\n\"\n",
    "                + \"\\n\".join([str(p) for p in missing])\n",
    "                + \"\\nPut them under SCFEA_DIR/data/ (or ./data/) and rerun.\"\n",
    "            )\n",
    "\n",
    "    # Export scFEA input CSV (genes × cells)\n",
    "    _ = export_scfea_input_from_adata(adata, SCFEA_INPUT_CSV)\n",
    "\n",
    "    # Run scFEA (write outputs under SCFEA_DIR/output/, then copy flux/balance into ./data/)\n",
    "    cmd = [\n",
    "        sys.executable, str(SCFEA_SRC),\n",
    "        \"--data_dir\", \"data\",\n",
    "        \"--input_dir\", \"input\",\n",
    "        \"--test_file\", SCFEA_TEST_FILE,\n",
    "        \"--moduleGene_file\", SCFEA_MODULE_GENE_FILE,\n",
    "        \"--stoichiometry_matrix\", SCFEA_STOICH_FILE,\n",
    "        \"--sc_imputation\", \"True\",\n",
    "        \"--output_flux_file\", \"output/Fibro_flux.csv\",\n",
    "        \"--output_balance_file\", \"output/Fibro_balance.csv\",\n",
    "    ]\n",
    "    print(\"Running scFEA with command:\")\n",
    "    print(\"  (cwd =\", SCFEA_DIR.resolve(), \")\")\n",
    "    print(\" \", \" \".join(cmd))\n",
    "\n",
    "    subprocess.run(cmd, cwd=str(SCFEA_DIR), check=True)\n",
    "\n",
    "    # Copy results into ./data/ so the downstream analysis is path-stable\n",
    "    scfea_flux_out = SCFEA_OUT_DIR / \"Fibro_flux.csv\"\n",
    "    scfea_bal_out  = SCFEA_OUT_DIR / \"Fibro_balance.csv\"\n",
    "\n",
    "    if not scfea_flux_out.exists():\n",
    "        raise FileNotFoundError(f\"scFEA finished but flux file not found: {scfea_flux_out}\")\n",
    "\n",
    "    shutil.copy2(scfea_flux_out, FLUX_CSV_PATH)\n",
    "    print(\"Copied scFEA flux ->\", FLUX_CSV_PATH.resolve())\n",
    "\n",
    "    if scfea_bal_out.exists():\n",
    "        shutil.copy2(scfea_bal_out, BALANCE_CSV_PATH)\n",
    "        print(\"Copied scFEA balance ->\", BALANCE_CSV_PATH.resolve())\n",
    "    else:\n",
    "        print(\"WARNING: scFEA balance file not found:\", scfea_bal_out)\n",
    "\n",
    "# 4) Load scFEA flux and match cell IDs\n",
    "flux_df = pd.read_csv(FLUX_CSV_PATH, index_col=0)\n",
    "\n",
    "flux_df.index = flux_df.index.astype(str).str.replace(\",\", \"_\", regex=False)\n",
    "\n",
    "common_cells = flux_df.index.intersection(adata.obs_names)\n",
    "if len(common_cells) == 0:\n",
    "    raise ValueError(\"No overlapping cell IDs between flux CSV and AnnData.\")\n",
    "\n",
    "flux_df = flux_df.loc[common_cells].copy()\n",
    "adata   = adata[common_cells].copy()\n",
    "\n",
    "print(\"Matched cells:\", len(common_cells))\n",
    "print(\"flux_df shape (cells × modules):\", flux_df.shape)\n",
    "print(\"adata shape (cells × genes):\", adata.shape)\n",
    "print(\"n_subtypes:\", adata.obs[SUBTYPE_KEY].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd61b1",
   "metadata": {
    "id": "c2fd61b1"
   },
   "source": [
    "## Core analysis\n",
    "\n",
    "For each module, compute subtype-wise mean flux, then perform **row-wise z-scoring** (module-centered) across subtypes.  \n",
    "Select the **top-k modules per subtype** (by z-score) as subtype “signature” modules, take the union set, and visualize as a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e9fa0",
   "metadata": {
    "id": "933e9fa0"
   },
   "outputs": [],
   "source": [
    "flux_by_subtype = flux_df.groupby(adata.obs[SUBTYPE_KEY]).mean().T\n",
    "\n",
    "flux_z = flux_by_subtype.copy()\n",
    "flux_z = flux_z.sub(flux_z.mean(axis=1), axis=0)\n",
    "flux_z = flux_z.div(flux_z.std(axis=1, ddof=0).replace(0, np.nan), axis=0).fillna(0.0)\n",
    "\n",
    "modules_per_subtype = {}\n",
    "for st in flux_z.columns:\n",
    "    modules_per_subtype[st] = (\n",
    "        flux_z[st].sort_values(ascending=False).head(TOP_K).index.tolist()\n",
    "    )\n",
    "\n",
    "selected_modules = []\n",
    "for st in flux_z.columns:\n",
    "    for m in modules_per_subtype[st]:\n",
    "        if m not in selected_modules:\n",
    "            selected_modules.append(m)\n",
    "\n",
    "print(\"Selected modules (union) =\", len(selected_modules))\n",
    "print(\"Example (first 10):\", selected_modules[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a04aa7",
   "metadata": {
    "id": "69a04aa7"
   },
   "outputs": [],
   "source": [
    "mod_info = pd.read_csv(MODULE_INFO_PATH, index_col=0)\n",
    "\n",
    "required_cols = {\"Compound_IN_name\", \"Compound_OUT_name\"}\n",
    "missing = required_cols - set(mod_info.columns)\n",
    "if missing:\n",
    "    raise KeyError(f\"Module info CSV is missing columns: {sorted(missing)}\")\n",
    "\n",
    "mod_info[\"pretty\"] = (\n",
    "    mod_info.index.astype(str)\n",
    "    + \": \"\n",
    "    + mod_info[\"Compound_IN_name\"].astype(str)\n",
    "    + \" \\u2192 \"\n",
    "    + mod_info[\"Compound_OUT_name\"].astype(str)\n",
    ")\n",
    "\n",
    "flux_sel = flux_z.loc[selected_modules].copy()\n",
    "\n",
    "subtype_order = list(pd.unique(adata.obs[SUBTYPE_KEY]))\n",
    "subtype_order = [st for st in subtype_order if st in flux_sel.columns]\n",
    "flux_sel = flux_sel[subtype_order]\n",
    "\n",
    "row_labels = []\n",
    "for m in flux_sel.index:\n",
    "    row_labels.append(mod_info.loc[m, \"pretty\"] if m in mod_info.index else m)\n",
    "\n",
    "flux_sel_labeled = flux_sel.copy()\n",
    "flux_sel_labeled.index = row_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b69ce",
   "metadata": {
    "id": "6e1b69ce"
   },
   "outputs": [],
   "source": [
    "def plot_flux_heatmap(\n",
    "    df_modules_x_subtypes: pd.DataFrame,\n",
    "    vmin: float = -2,\n",
    "    vmax: float =  2,\n",
    "    figsize=(12, 4),\n",
    "    out_pdf: Path = OUT_DIR / \"scFEA_flux_signature_fibro.pdf\",\n",
    "    out_svg: Path = OUT_DIR / \"scFEA_flux_signature_fibro.svg\",\n",
    "):\n",
    "    cmap = LinearSegmentedColormap.from_list(\n",
    "        \"flux_cmap\",\n",
    "        [\"#bbd9f2\", \"#c9e0f4\", \"#d7e7f7\", \"#f9fcf7\",\n",
    "         \"#e8a8c2\", \"#e084a9\", \"#a31515\"]\n",
    "    )\n",
    "\n",
    "    mat = df_modules_x_subtypes.values\n",
    "    row_names = df_modules_x_subtypes.index.tolist()\n",
    "    col_names = df_modules_x_subtypes.columns.tolist()\n",
    "    n_rows, n_cols = mat.shape\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    im = ax.imshow(\n",
    "        mat, aspect=\"auto\", interpolation=\"nearest\", cmap=cmap,\n",
    "        vmin=vmin, vmax=vmax, origin=\"upper\"\n",
    "    )\n",
    "    im.set_rasterized(True)\n",
    "    ax.grid(False)\n",
    "\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            ax.add_patch(Rectangle((j - 0.5, i - 0.5), 1.0, 1.0,\n",
    "                                   fill=False, edgecolor=\"black\", linewidth=0.8))\n",
    "    ax.add_patch(Rectangle((-0.5, -0.5), n_cols, n_rows,\n",
    "                           fill=False, edgecolor=\"black\", linewidth=1.2))\n",
    "\n",
    "    ax.set_xticks(np.arange(n_cols))\n",
    "    ax.set_xticklabels(col_names, rotation=60, ha=\"right\", va=\"top\", fontsize=9)\n",
    "    ax.set_yticks(np.arange(n_rows))\n",
    "    ax.set_yticklabels(row_names, fontsize=7.5)\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xlim(-0.5, n_cols - 0.5)\n",
    "    ax.set_ylim(n_rows - 0.5, -0.5)\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.03, pad=0.02)\n",
    "    cbar.set_label(\"Predicted metabolic flux (row z-score)\", rotation=90)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_pdf, dpi=300, bbox_inches=\"tight\")\n",
    "    fig.savefig(out_svg, dpi=300, bbox_inches=\"tight\")\n",
    "    return fig, ax\n",
    "\n",
    "_ = plot_flux_heatmap(flux_sel_labeled, figsize=(12, max(3, 0.18 * flux_sel_labeled.shape[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb904b8",
   "metadata": {
    "id": "afb904b8"
   },
   "source": [
    "## Results & exports\n",
    "\n",
    "This section writes all key artifacts to disk and prints the final output paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8237d",
   "metadata": {
    "id": "d9b8237d"
   },
   "outputs": [],
   "source": [
    "flux_by_subtype.to_csv(OUT_DIR / \"flux_mean_by_subtype_modules_x_subtypes.csv\")\n",
    "flux_z.to_csv(OUT_DIR / \"flux_row_zscore_modules_x_subtypes.csv\")\n",
    "flux_sel.to_csv(OUT_DIR / \"flux_row_zscore_selected_modules_x_subtypes.csv\")\n",
    "\n",
    "rows = []\n",
    "for st, mods in modules_per_subtype.items():\n",
    "    for rank, m in enumerate(mods, start=1):\n",
    "        pretty = mod_info.loc[m, \"pretty\"] if m in mod_info.index else m\n",
    "        rows.append({\n",
    "            \"subtype\": st,\n",
    "            \"rank\": rank,\n",
    "            \"module_id\": m,\n",
    "            \"module_pretty\": pretty,\n",
    "            \"zscore\": float(flux_z.loc[m, st]),\n",
    "        })\n",
    "top_table = pd.DataFrame(rows)\n",
    "top_table.to_csv(OUT_DIR / \"top_modules_per_subtype.csv\", index=False)\n",
    "\n",
    "adata_out = adata.copy()\n",
    "selected_flux_cell = flux_df[selected_modules].copy()\n",
    "adata_out.obsm[\"scfea_flux_selected\"] = selected_flux_cell.values\n",
    "adata_out.uns[\"scfea_flux_selected_columns\"] = selected_flux_cell.columns.tolist()\n",
    "adata_out.write_h5ad(OUT_DIR / \"Fibro_scFEA_matched_cells_with_selected_flux.h5ad\")\n",
    "\n",
    "print(\"Wrote outputs to:\", OUT_DIR.resolve())\n",
    "for p in [\n",
    "    OUT_DIR / \"scFEA_flux_signature_fibro.pdf\",\n",
    "    OUT_DIR / \"scFEA_flux_signature_fibro.svg\",\n",
    "    OUT_DIR / \"top_modules_per_subtype.csv\",\n",
    "    OUT_DIR / \"flux_row_zscore_selected_modules_x_subtypes.csv\",\n",
    "    OUT_DIR / \"Fibro_scFEA_matched_cells_with_selected_flux.h5ad\",\n",
    "]:\n",
    "    print(\" -\", p)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
