{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ba182f",
   "metadata": {},
   "source": [
    "# inferCNV (infercnvpy)\n",
    "\n",
    "**Design goals (for GitHub / peer review):**\n",
    "- All analysis parameters are collected in `CONFIG`.\n",
    "- All paths are **relative** to the repository root.\n",
    "- All outputs are written under `results/infercnv/`.\n",
    "- No cell outputs are stored in this notebook.\n",
    "\n",
    "**Input used in this project**\n",
    "- `data/1_Hepato_count.h5ad` (treated as the input to this notebook)\n",
    "\n",
    "> Notes  \n",
    "> - `infercnvpy` expects **normalized and log-transformed** expression values (log-space).  \n",
    "> - Genomic coordinates must be available in `adata.var[[\"chromosome\",\"start\",\"end\"]]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# CONFIG (edit paths/keys here)\n",
    "# =========================\n",
    "CONFIG = {\n",
    "    # ---- Input ----\n",
    "    \"INPUT_H5AD\": Path(\"data/1_Hepato_count.h5ad\"),\n",
    "\n",
    "    # ---- Output root ----\n",
    "    \"OUTDIR\": Path(\"results/infercnv\"),\n",
    "\n",
    "    # ---- Reproducibility ----\n",
    "    \"SEED\": 0,\n",
    "    \"FIG_DPI\": 200,\n",
    "\n",
    "    # ---- Expression matrix for infercnvpy ----\n",
    "    # infercnvpy expects log-transformed data (log-space).\n",
    "    #\n",
    "    # If your `INPUT_H5AD` stores raw counts in `adata.X` (common for \"*_count*.h5ad\"),\n",
    "    # set AUTO_LOG_NORMALIZE=True to automatically create a log-normalized layer.\n",
    "    \"AUTO_LOG_NORMALIZE\": True,\n",
    "    \"COUNTS_LAYER\": \"counts\",   # used when AUTO_LOG_NORMALIZE=True (falls back to X if missing)\n",
    "    \"TARGET_SUM\": 1e4,          # normalize_total target sum\n",
    "\n",
    "    # ---- Genomic gene positions ----\n",
    "    # Option A (recommended offline): local 4-column TSV with:\n",
    "    #   gene_name    chromosome    start    end\n",
    "    # If the file is missing, the notebook can download it automatically.\n",
    "    \"GENE_POS_TSV\": Path(\"resources/hg38_gencode_v27.txt\"),\n",
    "    \"GENE_POS_URL\": \"https://data.broadinstitute.org/Trinity/CTAT/cnv/hg38_gencode_v27.txt\",\n",
    "\n",
    "    # Option B: use a (GENCODE) GTF file instead of the TSV above.\n",
    "    # If GTF_PATH is not None, the notebook will prefer the GTF.\n",
    "    \"GTF_PATH\": None,           # e.g. Path(\"resources/gencode.v38.annotation.gtf\")\n",
    "    \"GTF_GENE_ID\": \"gene_name\", # \"gene_name\" or \"gene_id\"\n",
    "    \"ADATA_GENE_ID\": None,      # None -> use adata.var_names, or set to a column in adata.var\n",
    "\n",
    "    # ---- Reference definition (normal cells) ----\n",
    "    # If REFERENCE_KEY is None, infercnvpy uses the average of all cells as reference.\n",
    "    # If you know which cells are \"normal\", set REFERENCE_KEY and REFERENCE_CAT.\n",
    "    \"REFERENCE_KEY\": \"type\",\n",
    "    \"REFERENCE_CAT\": [\"0\"],     # one or multiple categories in obs[REFERENCE_KEY]\n",
    "\n",
    "    # ---- Plotting ----\n",
    "    # Optional: restrict chromosome heatmaps to a subset of cells.\n",
    "    # Set PLOT_SUBSET_CAT=None to plot all cells.\n",
    "    \"PLOT_SUBSET_KEY\": \"type\",\n",
    "    \"PLOT_SUBSET_CAT\": [\"1\"],   # e.g. tumor cells only\n",
    "\n",
    "    # Grouping variable for heatmaps (e.g., \"subtype\" / \"leiden\" / \"sample\")\n",
    "    \"PLOT_GROUPBY\": \"subtype\",\n",
    "\n",
    "    # ---- infercnv parameters ----\n",
    "    \"WINDOW_SIZE\": 100,\n",
    "    \"STEP\": 10,\n",
    "    \"DYNAMIC_THRESHOLD\": 1.5,\n",
    "    \"EXCLUDE_CHROMS\": (\"chrX\", \"chrY\"),\n",
    "    \"N_JOBS\": None,\n",
    "\n",
    "    # ---- CNV embedding / clustering ----\n",
    "    \"LEIDEN_RES\": 0.3,\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Output directories\n",
    "# =========================\n",
    "DIRS = {\n",
    "    \"root\": CONFIG[\"OUTDIR\"],\n",
    "    \"fig\": CONFIG[\"OUTDIR\"] / \"figures\",\n",
    "    \"adata\": CONFIG[\"OUTDIR\"] / \"adata\",\n",
    "    \"tables\": CONFIG[\"OUTDIR\"] / \"tables\",\n",
    "}\n",
    "\n",
    "for d in DIRS.values():\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"[CONFIG] INPUT_H5AD={CONFIG['INPUT_H5AD']}\")\n",
    "print(f\"[CONFIG] OUTDIR={CONFIG['OUTDIR'].resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f9e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "from importlib.metadata import PackageNotFoundError, version\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# -------------------------\n",
    "# Reproducibility\n",
    "# -------------------------\n",
    "random.seed(CONFIG[\"SEED\"])\n",
    "np.random.seed(CONFIG[\"SEED\"])\n",
    "\n",
    "# Matplotlib defaults (vector-friendly fonts)\n",
    "mpl.rcParams[\"pdf.fonttype\"] = 42\n",
    "mpl.rcParams[\"ps.fonttype\"] = 42\n",
    "\n",
    "# Scanpy defaults\n",
    "sc.settings.verbosity = 2\n",
    "sc.settings.set_figure_params(dpi=CONFIG[\"FIG_DPI\"], facecolor=\"white\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def _v(pkg: str) -> str:\n",
    "    try:\n",
    "        return version(pkg)\n",
    "    except PackageNotFoundError:\n",
    "        return \"not-installed\"\n",
    "\n",
    "print(\"Versions:\")\n",
    "for pkg in [\"python\", \"numpy\", \"pandas\", \"scanpy\", \"anndata\", \"matplotlib\", \"scipy\", \"infercnvpy\"]:\n",
    "    print(f\" - {pkg}: {sys.version.split()[0] if pkg == 'python' else _v(pkg)}\")\n",
    "\n",
    "try:\n",
    "    import infercnvpy as cnv\n",
    "except Exception as e:\n",
    "    raise ImportError(\n",
    "        \"infercnvpy is required. Install it via `pip install infercnvpy` \"\n",
    "        \"or use the project's environment.yml / requirements.txt.\"\n",
    "    ) from e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b98faa",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01647413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input AnnData\n",
    "if not CONFIG[\"INPUT_H5AD\"].exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing input file: {CONFIG['INPUT_H5AD']}. \"\n",
    "        \"Place it under `data/` (recommended) or edit CONFIG['INPUT_H5AD'].\"\n",
    "    )\n",
    "\n",
    "adata = sc.read_h5ad(CONFIG[\"INPUT_H5AD\"])\n",
    "adata.var_names_make_unique()\n",
    "\n",
    "print(adata)\n",
    "\n",
    "# Ensure key obs columns exist (for plotting / reference definition)\n",
    "for k in [CONFIG[\"REFERENCE_KEY\"], CONFIG[\"PLOT_SUBSET_KEY\"], CONFIG[\"PLOT_GROUPBY\"]]:\n",
    "    if k is None:\n",
    "        continue\n",
    "    if k not in adata.obs.columns:\n",
    "        print(f\"[WARN] obs['{k}'] not found in input. You may need to update CONFIG.\")\n",
    "    else:\n",
    "        # work with string categories for robustness (e.g., '0'/'1')\n",
    "        adata.obs[k] = adata.obs[k].astype(str)\n",
    "\n",
    "# Optional: quick UMAP sanity check (if embeddings already exist)\n",
    "if \"X_umap\" in adata.obsm:\n",
    "    sc.pl.umap(adata, color=[k for k in [CONFIG['PLOT_GROUPBY'], CONFIG['REFERENCE_KEY']] if k in adata.obs], wspace=0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a97f8",
   "metadata": {},
   "source": [
    "## Expression preprocessing (log-normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f65caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a working copy so we don't modify the on-disk object\n",
    "adata_cnv = adata.copy()\n",
    "\n",
    "def _matrix_stats(X, seed: int = 0, n: int = 200_000):\n",
    "    \"\"\"Heuristic summary statistics for (sparse) expression matrices.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if sparse.issparse(X):\n",
    "        data = X.data\n",
    "        if data.size == 0:\n",
    "            return {\"dtype\": str(X.dtype), \"max\": 0.0, \"p99\": 0.0, \"intlike\": True}\n",
    "        idx = rng.choice(data.size, size=min(n, data.size), replace=False)\n",
    "        sample = data[idx]\n",
    "    else:\n",
    "        arr = np.asarray(X)\n",
    "        flat = arr.ravel()\n",
    "        idx = rng.choice(flat.size, size=min(n, flat.size), replace=False)\n",
    "        sample = flat[idx]\n",
    "    return {\n",
    "        \"dtype\": str(X.dtype),\n",
    "        \"max\": float(np.max(sample)),\n",
    "        \"p99\": float(np.quantile(sample, 0.99)),\n",
    "        \"intlike\": bool(np.all(np.isclose(sample, np.round(sample)))),\n",
    "    }\n",
    "\n",
    "CNV_LAYER = None  # None -> use adata_cnv.X\n",
    "\n",
    "if CONFIG[\"AUTO_LOG_NORMALIZE\"]:\n",
    "    # Decide whether `adata.X` already looks like log-normalized data.\n",
    "    stats_X = _matrix_stats(adata_cnv.X, seed=CONFIG[\"SEED\"])\n",
    "    looks_like_counts = (np.issubdtype(adata_cnv.X.dtype, np.integer)) or (stats_X[\"max\"] > 20 and stats_X[\"intlike\"])\n",
    "\n",
    "    print(\"[X stats]\", stats_X, \"| looks_like_counts:\", looks_like_counts)\n",
    "\n",
    "    if looks_like_counts:\n",
    "        # Build a log-normalized layer for infercnvpy.\n",
    "        base_layer = CONFIG[\"COUNTS_LAYER\"] if CONFIG[\"COUNTS_LAYER\"] in adata_cnv.layers else None\n",
    "        if base_layer is None:\n",
    "            print(\"[AUTO_LOG_NORMALIZE] Using adata.X as raw counts source.\")\n",
    "            adata_cnv.layers[\"log_norm\"] = adata_cnv.X.copy()\n",
    "        else:\n",
    "            print(f\"[AUTO_LOG_NORMALIZE] Using adata.layers['{base_layer}'] as raw counts source.\")\n",
    "            adata_cnv.layers[\"log_norm\"] = adata_cnv.layers[base_layer].copy()\n",
    "\n",
    "        sc.pp.normalize_total(adata_cnv, target_sum=CONFIG[\"TARGET_SUM\"], layer=\"log_norm\")\n",
    "        sc.pp.log1p(adata_cnv, layer=\"log_norm\")\n",
    "\n",
    "        CNV_LAYER = \"log_norm\"\n",
    "        print(\"[AUTO_LOG_NORMALIZE] Created adata.layers['log_norm'] for infercnvpy.\")\n",
    "    else:\n",
    "        print(\"[AUTO_LOG_NORMALIZE] adata.X does not look like raw counts. Using adata.X directly.\")\n",
    "else:\n",
    "    print(\"[AUTO_LOG_NORMALIZE] Disabled. infercnvpy will use adata.X (must be log-normalized).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff048b00",
   "metadata": {},
   "source": [
    "## Add genomic positions (adata.var)\n",
    "\n",
    "`infercnvpy` requires genomic positions for each gene, stored in:\n",
    "\n",
    "- `adata.var[\"chromosome\"]`\n",
    "- `adata.var[\"start\"]`\n",
    "- `adata.var[\"end\"]`\n",
    "\n",
    "This notebook supports two ways to annotate gene positions:\n",
    "\n",
    "1. **GTF (preferred if you already have it)**: set `CONFIG[\"GTF_PATH\"]` to a local GENCODE GTF file.  \n",
    "2. **TSV mapping file**: `CONFIG[\"GENE_POS_TSV\"]` (auto-download from `CONFIG[\"GENE_POS_URL\"]` if missing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e888d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def _download_if_missing(url: str, dest: Path):\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dest.exists():\n",
    "        return\n",
    "    print(f\"[DOWNLOAD] {url} -> {dest}\")\n",
    "    urlretrieve(url, dest)\n",
    "\n",
    "def _ensure_chr_prefix(chrom):\n",
    "    if pd.isna(chrom):\n",
    "        return np.nan\n",
    "    chrom = str(chrom)\n",
    "    if chrom.startswith(\"chr\"):\n",
    "        return chrom\n",
    "    if chrom in {\"X\", \"Y\"}:\n",
    "        return f\"chr{chrom}\"\n",
    "    if chrom in {\"M\", \"MT\"}:\n",
    "        return \"chrM\"\n",
    "    if chrom.isdigit():\n",
    "        return f\"chr{chrom}\"\n",
    "    return \"chr\" + chrom  # fallback\n",
    "\n",
    "n_genes_before = adata_cnv.n_vars\n",
    "\n",
    "if CONFIG[\"GTF_PATH\"] is not None:\n",
    "    gtf_path = Path(CONFIG[\"GTF_PATH\"])\n",
    "    if not gtf_path.exists():\n",
    "        raise FileNotFoundError(f\"GTF not found: {gtf_path}\")\n",
    "    cnv.io.genomic_position_from_gtf(\n",
    "        gtf_file=gtf_path,\n",
    "        adata=adata_cnv,\n",
    "        gtf_gene_id=CONFIG[\"GTF_GENE_ID\"],\n",
    "        adata_gene_id=CONFIG[\"ADATA_GENE_ID\"],\n",
    "        inplace=True,\n",
    "    )\n",
    "else:\n",
    "    # TSV option (auto-download if needed)\n",
    "    tsv_path = Path(CONFIG[\"GENE_POS_TSV\"])\n",
    "    _download_if_missing(CONFIG[\"GENE_POS_URL\"], tsv_path)\n",
    "\n",
    "    # Expected columns: gene_name, chromosome, start, end (no header in Broad's file)\n",
    "    pos = pd.read_csv(\n",
    "        tsv_path,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=[\"gene_name\", \"chromosome\", \"start\", \"end\"],\n",
    "        dtype={\"gene_name\": str, \"chromosome\": str},\n",
    "        on_bad_lines=\"skip\",\n",
    "    ).drop_duplicates(subset=[\"gene_name\"])\n",
    "\n",
    "    # Map by gene id (var_names by default)\n",
    "    if CONFIG[\"ADATA_GENE_ID\"] is None:\n",
    "        gene_ids = pd.Index(adata_cnv.var_names.astype(str))\n",
    "    else:\n",
    "        if CONFIG[\"ADATA_GENE_ID\"] not in adata_cnv.var.columns:\n",
    "            raise KeyError(f\"adata.var['{CONFIG['ADATA_GENE_ID']}'] not found\")\n",
    "        gene_ids = pd.Index(adata_cnv.var[CONFIG[\"ADATA_GENE_ID\"]].astype(str))\n",
    "\n",
    "    pos = pos.set_index(\"gene_name\").reindex(gene_ids)\n",
    "\n",
    "    chrom = pos[\"chromosome\"].map(_ensure_chr_prefix)\n",
    "    start = pd.to_numeric(pos[\"start\"], errors=\"coerce\")\n",
    "    end = pd.to_numeric(pos[\"end\"], errors=\"coerce\")\n",
    "\n",
    "    # Assign by position (avoid pandas index alignment issues when ADATA_GENE_ID != var_names)\n",
    "    adata_cnv.var[\"chromosome\"] = chrom.to_numpy()\n",
    "    adata_cnv.var[\"start\"] = start.to_numpy()\n",
    "    adata_cnv.var[\"end\"] = end.to_numpy()\n",
    "\n",
    "# Filter genes without genomic coordinates\n",
    "valid = (\n",
    "    adata_cnv.var[\"chromosome\"].notna()\n",
    "    & pd.notnull(adata_cnv.var[\"start\"])\n",
    "    & pd.notnull(adata_cnv.var[\"end\"])\n",
    ")\n",
    "\n",
    "n_valid = int(valid.sum())\n",
    "print(f\"[GENE_POS] {n_valid}/{n_genes_before} genes have valid genomic positions.\")\n",
    "\n",
    "adata_cnv = adata_cnv[:, valid].copy()\n",
    "\n",
    "# Now that NaNs are removed, cast to integer coordinates for downstream use\n",
    "adata_cnv.var[\"start\"] = adata_cnv.var[\"start\"].astype(int)\n",
    "adata_cnv.var[\"end\"] = adata_cnv.var[\"end\"].astype(int)\n",
    "\n",
    "print(\"[After gene filtering]\", adata_cnv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f6a29",
   "metadata": {},
   "source": [
    "## Run infercnvpy\n",
    "\n",
    "This computes a smoothed, denoised expression matrix along the genome and stores it in:\n",
    "\n",
    "- `adata_cnv.obsm[\"X_cnv\"]` (when `key_added=\"cnv\"`)\n",
    "- metadata in `adata_cnv.uns[\"cnv\"]`\n",
    "\n",
    "If you provide known normal cells via `REFERENCE_KEY` / `REFERENCE_CAT`, infercnvpy uses them as the reference background.\n",
    "If not, it uses the average of all cells as reference (default behavior).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79caf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve reference settings\n",
    "reference_key = CONFIG[\"REFERENCE_KEY\"]\n",
    "reference_cat = CONFIG[\"REFERENCE_CAT\"]\n",
    "\n",
    "if reference_key is not None:\n",
    "    if reference_key not in adata_cnv.obs.columns:\n",
    "        print(f\"[WARN] reference_key='{reference_key}' not found in adata.obs. Falling back to average-of-all-cells reference.\")\n",
    "        reference_key = None\n",
    "        reference_cat = None\n",
    "    else:\n",
    "        # Ensure categories are strings\n",
    "        adata_cnv.obs[reference_key] = adata_cnv.obs[reference_key].astype(str)\n",
    "\n",
    "        if reference_cat is not None:\n",
    "            reference_cat = [str(x) for x in reference_cat]\n",
    "            missing = sorted(set(reference_cat) - set(adata_cnv.obs[reference_key].unique()))\n",
    "            if missing:\n",
    "                print(f\"[WARN] reference_cat values not found in obs['{reference_key}']: {missing}\")\n",
    "                print(\"[WARN] Falling back to average-of-all-cells reference.\")\n",
    "                reference_key = None\n",
    "                reference_cat = None\n",
    "\n",
    "print(\"[infercnv] reference_key =\", reference_key)\n",
    "print(\"[infercnv] reference_cat =\", reference_cat)\n",
    "print(\"[infercnv] layer =\", CNV_LAYER)\n",
    "\n",
    "cnv.tl.infercnv(\n",
    "    adata_cnv,\n",
    "    reference_key=reference_key,\n",
    "    reference_cat=reference_cat,\n",
    "    window_size=CONFIG[\"WINDOW_SIZE\"],\n",
    "    step=CONFIG[\"STEP\"],\n",
    "    dynamic_threshold=CONFIG[\"DYNAMIC_THRESHOLD\"],\n",
    "    exclude_chromosomes=CONFIG[\"EXCLUDE_CHROMS\"],\n",
    "    n_jobs=CONFIG[\"N_JOBS\"],\n",
    "    layer=CNV_LAYER,\n",
    "    key_added=\"cnv\",\n",
    ")\n",
    "\n",
    "print(\"CNV matrix stored in:\", [k for k in adata_cnv.obsm_keys() if k.startswith(\"X_\") and \"cnv\" in k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f2cc0",
   "metadata": {},
   "source": [
    "## Chromosome-level heatmaps\n",
    "\n",
    "We generate two common plots:\n",
    "\n",
    "1. `chromosome_heatmap`: per-cell CNV heatmap along the genome (grouped by `PLOT_GROUPBY`)  \n",
    "2. `chromosome_heatmap_summary`: average CNV profile per group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom blue-white-red colormap (optional; change if you prefer the default 'bwr')\n",
    "colors = [\"#222d6a\", \"#3a4891\", \"#78a1df\", \"#ffffff\", \"#af6c81\", \"#964e5a\", \"#6d3643\"]\n",
    "custom_cnv = mcolors.LinearSegmentedColormap.from_list(\"custom_cnv\", colors)\n",
    "\n",
    "def _savefig(obj, outpath):\n",
    "    outpath = Path(outpath)\n",
    "    outpath.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fig = None\n",
    "    if obj is None:\n",
    "        fig = plt.gcf()\n",
    "    elif hasattr(obj, \"get_figure\"):\n",
    "        fig = obj.get_figure()\n",
    "    elif hasattr(obj, \"figure\"):\n",
    "        fig = obj.figure\n",
    "    elif isinstance(obj, dict):\n",
    "        for v in obj.values():\n",
    "            if hasattr(v, \"get_figure\"):\n",
    "                fig = v.get_figure()\n",
    "                break\n",
    "    if fig is None:\n",
    "        fig = plt.gcf()\n",
    "\n",
    "    fig.savefig(outpath, bbox_inches=\"tight\")\n",
    "    return fig\n",
    "\n",
    "# Subset cells for plotting if requested\n",
    "adata_plot = adata_cnv\n",
    "if CONFIG[\"PLOT_SUBSET_CAT\"] is not None:\n",
    "    key = CONFIG[\"PLOT_SUBSET_KEY\"]\n",
    "    if key in adata_plot.obs:\n",
    "        keep = adata_plot.obs[key].astype(str).isin([str(x) for x in CONFIG[\"PLOT_SUBSET_CAT\"]])\n",
    "        adata_plot = adata_plot[keep].copy()\n",
    "        print(f\"[PLOT] Subset: {adata_plot.n_obs} cells kept by {key} in {CONFIG['PLOT_SUBSET_CAT']}\")\n",
    "    else:\n",
    "        print(f\"[WARN] PLOT_SUBSET_KEY='{key}' not found in obs. Plotting all cells.\")\n",
    "\n",
    "groupby = CONFIG[\"PLOT_GROUPBY\"] if CONFIG[\"PLOT_GROUPBY\"] in adata_plot.obs else None\n",
    "if groupby is None:\n",
    "    raise KeyError(f\"PLOT_GROUPBY='{CONFIG['PLOT_GROUPBY']}' not found in adata.obs.\")\n",
    "\n",
    "# 1) Per-cell CNV heatmap\n",
    "ax = cnv.pl.chromosome_heatmap(\n",
    "    adata_plot,\n",
    "    groupby=groupby,\n",
    "    cmap=custom_cnv,\n",
    "    show=False,\n",
    ")\n",
    "_savefig(ax, DIRS[\"fig\"] / \"chromosome_heatmap.pdf\")\n",
    "_savefig(ax, DIRS[\"fig\"] / \"chromosome_heatmap.svg\")\n",
    "plt.close(\"all\")\n",
    "\n",
    "# 2) Group-average CNV heatmap\n",
    "ax = cnv.pl.chromosome_heatmap_summary(\n",
    "    adata_plot,\n",
    "    groupby=groupby,\n",
    "    cmap=custom_cnv,\n",
    "    show=False,\n",
    ")\n",
    "_savefig(ax, DIRS[\"fig\"] / \"chromosome_heatmap_summary.pdf\")\n",
    "_savefig(ax, DIRS[\"fig\"] / \"chromosome_heatmap_summary.svg\")\n",
    "plt.close(\"all\")\n",
    "\n",
    "print(\"[PLOT] Saved figures to:\", DIRS[\"fig\"].resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef656408",
   "metadata": {},
   "source": [
    "## CNV embedding, clustering, and CNV score\n",
    "\n",
    "infercnvpy provides Scanpy-like wrappers to work on the CNV matrix:\n",
    "\n",
    "- `cnv.tl.pca` → `cnv.pp.neighbors` → `cnv.tl.leiden` → `cnv.tl.umap`\n",
    "- `cnv.tl.cnv_score` assigns each CNV cluster a score (higher = more aberrant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a36456",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8434444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CNV-based PCA / neighbors / Leiden / UMAP\n",
    "cnv.tl.pca(adata_cnv)  # stores CNV PCA in adata.obsm['X_cnv_pca']\n",
    "cnv.pp.neighbors(adata_cnv)  # stores graph in adata.obsp['cnv_neighbors_*']\n",
    "cnv.tl.leiden(adata_cnv, resolution=CONFIG[\"LEIDEN_RES\"])\n",
    "cnv.tl.umap(adata_cnv)\n",
    "cnv.tl.cnv_score(adata_cnv)\n",
    "\n",
    "# Plot CNV UMAP\n",
    "colors_to_plot = [\"cnv_leiden\", \"cnv_score\"]\n",
    "if CONFIG[\"PLOT_GROUPBY\"] in adata_cnv.obs:\n",
    "    colors_to_plot.append(CONFIG[\"PLOT_GROUPBY\"])\n",
    "if CONFIG[\"REFERENCE_KEY\"] in adata_cnv.obs:\n",
    "    colors_to_plot.append(CONFIG[\"REFERENCE_KEY\"])\n",
    "\n",
    "ax = cnv.pl.umap(\n",
    "    adata_cnv,\n",
    "    color=colors_to_plot,\n",
    "    wspace=0.4,\n",
    "    show=False,\n",
    ")\n",
    "_savefig(ax, DIRS[\"fig\"] / \"cnv_umap.pdf\")\n",
    "_savefig(ax, DIRS[\"fig\"] / \"cnv_umap.svg\")\n",
    "plt.close(\"all\")\n",
    "\n",
    "print(\"[PLOT] Saved CNV UMAP to:\", (DIRS[\"fig\"] / \"cnv_umap.pdf\").resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed AnnData with CNV results\n",
    "out_h5ad = DIRS[\"adata\"] / \"1_Hepato_count.infercnv.h5ad\"\n",
    "adata_cnv.write_h5ad(out_h5ad, compression=\"gzip\")\n",
    "print(\"[EXPORT] Saved:\", out_h5ad.resolve())\n",
    "\n",
    "# Optional: export per-cell annotations to a TSV (useful for reviewers)\n",
    "obs_export = DIRS[\"tables\"] / \"cell_metadata_with_cnv.tsv\"\n",
    "cols = [c for c in [CONFIG[\"PLOT_GROUPBY\"], CONFIG[\"REFERENCE_KEY\"], \"cnv_leiden\", \"cnv_score\"] if c in adata_cnv.obs]\n",
    "adata_cnv.obs[cols].to_csv(obs_export, sep=\"\\t\")\n",
    "print(\"[EXPORT] Saved:\", obs_export.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
